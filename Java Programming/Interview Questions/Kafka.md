Below is a **senior-level, concept-first explanation of Kafka fundamentals**, focusing on **why Kafka exists, how it works internally, and the trade-offs interviewers care about**.

---

# 1Ô∏è‚É£ Kafka Fundamentals (Still Asked, But Deep)

---

## What is **Kafka** and why is it used?

### **Concept**

Kafka is a **distributed, append-only, durable event log** designed to handle **high-throughput, real-time data streams**.

It is used when you need:

* Massive throughput
* Horizontal scalability
* Fault tolerance
* Event replay
* Loose coupling between producers and consumers

üí° **Interview one-liner**

> Kafka is a distributed commit log for real-time data pipelines.

---

## Kafka vs traditional message queue (RabbitMQ / ActiveMQ) ‚≠ê

### **Traditional MQ**

* Message-centric
* Broker pushes messages
* Messages deleted after consumption
* Optimized for task queues

---

### **Kafka**

* Log-centric
* Consumers pull messages
* Messages retained for a configured time
* Optimized for streaming & replay

---

### **Key differences**

| Aspect            | Traditional MQ | Kafka           |
| ----------------- | -------------- | --------------- |
| Model             | Queue          | Distributed log |
| Throughput        | Medium         | Very high       |
| Message retention | Short-lived    | Configurable    |
| Replay            | ‚ùå              | ‚úÖ               |
| Scaling           | Limited        | Horizontal      |
| Consumers         | Competing      | Independent     |

üí° **Senior insight**

> RabbitMQ moves messages; Kafka stores events.

---

## What problems does Kafka solve?

Kafka solves:

* High-volume event ingestion
* Fan-out to multiple consumers
* Decoupling producers and consumers
* Event replay & recovery
* Back-pressure handling
* Real-time analytics pipelines

üí° **Interview framing**

> Kafka turns data movement into a scalable, replayable log.

---

## Is Kafka a **message queue** or a **streaming platform**?

### **Correct answer**

> Kafka is **both**, but fundamentally a **streaming platform**.

* Can behave like a queue
* But core abstraction is **event streaming**
* Consumers manage their own offsets

üí° **Interview gold**

> Kafka is not about deleting messages ‚Äî it‚Äôs about retaining events.

---

## Why is Kafka **fast**?

### **Key reasons**

1. **Sequential disk writes** (append-only)
2. **Zero-copy I/O** (sendfile)
3. **Batching** (producer & broker)
4. **Page cache usage**
5. **No random disk access**
6. **Pull-based consumption**
7. **Minimal broker logic**

üí° **Senior insight**

> Kafka is fast because it treats disk like memory and memory like disk.

---

## What is a **Kafka cluster**?

### **Concept**

A Kafka cluster is:

> **A group of Kafka brokers working together to store and serve data.**

Responsibilities:

* Distribute partitions
* Replicate data
* Handle failures
* Balance load

---

## What is a **Kafka broker**?

### **Concept**

A broker is:

> **A Kafka server that stores partitions and serves producers/consumers.**

Responsibilities:

* Store partition data
* Handle read/write requests
* Manage replication
* Participate in leader elections

üí° **Interview clarity**

> Brokers are storage + network servers, not message processors.

---

## What is a **topic**?

### **Concept**

A topic is:

> **A logical category or stream of events.**

* Topics are split into partitions
* Topics are immutable logs
* Topics do not enforce schema (Kafka itself)

---

## What is a **partition**?

### **Concept**

A partition is:

> **An ordered, immutable sequence of records within a topic.**

* Each partition is an independent log
* Stored on a single broker (leader)
* Replicated across brokers

üí° **Interview one-liner**

> Partitions are the unit of parallelism in Kafka.

---

## Why are **partitions important**? ‚≠ê

Partitions enable:

* Parallel writes
* Parallel reads
* Horizontal scalability
* Fault tolerance
* Ordering guarantees (within partition)

üí° **Senior insight**

> No partitions ‚Üí no scalability.

---

# 2Ô∏è‚É£ Topics, Partitions & Ordering (VERY COMMON)

---

## How does Kafka **guarantee ordering**?

### **Rule**

> Kafka guarantees ordering **within a single partition**.

Why:

* Messages are appended sequentially
* Consumers read in offset order

---

## Is ordering guaranteed **across partitions**?

### ‚ùå **No**

* Partitions are independent
* No global ordering
* Consumers read partitions in parallel

üí° **Interview trap**

> Kafka trades global ordering for scalability.

---

## How do you decide **number of partitions**?

### **Senior factors**

1. Expected throughput
2. Consumer parallelism
3. Broker count
4. Future growth
5. Key distribution

Rule of thumb:

> Partitions ‚â• max concurrent consumers

üí° **Interview insight**

> Partitions define your scalability ceiling.

---

## Can you **change number of partitions later**?

### ‚úÖ **Yes**, but with consequences

* You can **increase** partitions
* You **cannot decrease** partitions
* Ordering for existing keys may break

---

## What happens to ordering when **partitions increase**?

### **Important**

* Existing messages remain ordered
* New messages may go to new partitions
* Key-to-partition mapping changes

üí° **Senior warning**

> Increasing partitions can break per-key ordering guarantees.

---

## What happens if a **partition leader fails**?

### **Kafka behavior**

1. Detect broker failure
2. Elect new leader from ISR
3. Clients redirect traffic
4. Consumption resumes

Data safety depends on:

* Replication factor
* min.insync.replicas
* Producer acks

üí° **Interview clarity**

> Kafka handles failures automatically, not magically.

---

## How does Kafka handle **partition rebalancing**?

### **When rebalancing happens**

* Consumer joins/leaves
* Partition count changes
* Broker failure

### **What happens**

* Partitions reassigned to consumers
* Consumers pause briefly
* Offsets reassigned

üí° **Senior insight**

> Rebalancing trades availability for correctness.

---

## What is **partition skew**?

### **Concept**

Partition skew occurs when:

> Some partitions receive significantly more traffic than others.

Causes:

* Poor key choice
* Hot keys
* Uneven hashing

Impact:

* Hot brokers
* Increased latency
* Underutilized consumers

---

## What happens if one partition is **very hot**? ‚≠ê

### **Symptoms**

* One consumer overloaded
* Increased lag
* Broker CPU spikes
* Throughput bottleneck

### **Why**

> A partition can only be processed by **one consumer at a time**.

---

## How do you handle **uneven message load**?

### **Senior strategies**

1Ô∏è‚É£ **Choose better keys**

* Avoid constant keys
* Use composite keys
* Hash business keys

2Ô∏è‚É£ **Increase partitions (carefully)**

* Plan upfront
* Avoid frequent changes

3Ô∏è‚É£ **Custom partitioner**

* Distribute load intelligently

4Ô∏è‚É£ **Split hot topics**

* Separate streams
* Domain-based topics

5Ô∏è‚É£ **Async processing**

* Reduce consumer processing time

üí° **Interview gold**

> Most Kafka performance issues are key-design issues.

---

## ‚úÖ Final Interview-Ready Summary

* Kafka is a distributed event log
* It solves high-throughput, scalable data streaming
* Kafka ‚â† traditional message queue
* Messages are retained and replayable
* Kafka is fast due to sequential I/O and batching
* Topics are logical streams
* Partitions are ordered logs and scaling units
* Ordering is guaranteed only within a partition
* Partition count defines scalability
* Increasing partitions can affect ordering
* Leaders handle writes; replicas provide durability
* Rebalancing redistributes partitions
* Partition skew causes hotspots
* Uneven load is usually a key design problem

---
Below is a **senior-level, concept-first explanation** of **Kafka Producers and Consumers**, focusing on **internal mechanics, guarantees, and real production trade-offs**. This is exactly the depth Kafka interviews expect.

---

# 3Ô∏è‚É£ Kafka Producers (üî• HIGH SIGNAL)

---

## How does **Kafka Producer work internally**?

### **High-level flow**

1. Producer creates a record
2. Serializer converts key/value to bytes
3. Partitioner decides **which partition**
4. Record goes into a **batch**
5. Batch sent to broker leader
6. Broker writes to log
7. Acknowledgment sent back
8. Callback executed

üí° **Key idea**

> Producer is asynchronous by default and heavily optimized for batching.

---

## What is **producer batching**?

### **Concept**

Producer does **not** send each message immediately.
It groups multiple records into a **batch per partition**.

Benefits:

* Fewer network calls
* Better disk I/O
* Higher throughput

üí° **Interview one-liner**

> Kafka achieves throughput via batching, not raw speed.

---

## What is **linger.ms**?

### **Concept**

`linger.ms` defines:

> **How long the producer waits to accumulate a batch before sending.**

* `0` ‚Üí send immediately
* Higher value ‚Üí better batching, higher latency

üí° **Trade-off**

> Throughput ‚Üë, Latency ‚Üë

---

## What is **batch.size**?

### **Concept**

Maximum size (in bytes) of a batch **per partition**.

* Larger batch ‚Üí better throughput
* Too large ‚Üí memory pressure & latency

üí° **Important**

> batch.size is a *soft limit* ‚Äî linger.ms can send smaller batches.

---

## What is **acks**?

### **Concept**

`acks` defines:

> **How many brokers must acknowledge a write before producer considers it successful.**

It controls **durability vs latency**.

---

## Difference between **acks=0, 1, all** ‚≠ê

| acks | Meaning           | Durability | Latency   |
| ---- | ----------------- | ---------- | --------- |
| 0    | Fire-and-forget   | ‚ùå None     | üî• Lowest |
| 1    | Leader only       | ‚ö†Ô∏è Medium  | ‚ö° Fast    |
| all  | Leader + replicas | ‚úÖ Strong   | üê¢ Slower |

üí° **Senior stance**

> acks=all is required for correctness-critical systems (banking).

---

## What is **idempotent producer**?

### **Concept**

Idempotent producer ensures:

> **Even if retries happen, Kafka will not write duplicates.**

How:

* Producer ID (PID)
* Sequence numbers per partition
* Broker detects duplicates

üí° **Key rule**

> Idempotence works **per partition per producer session**.

---

## How does Kafka guarantee **no duplicate messages**?

Kafka itself **does not guarantee no duplicates by default**.

Duplicates are avoided when:

* `enable.idempotence=true`
* `acks=all`
* Proper retry configuration

üí° **Interview clarity**

> Kafka guarantees *at-least-once* by default, *exactly-once* with configuration.

---

## What is **message key**?

### **Concept**

Message key determines:

> **Which partition a message goes to.**

* Same key ‚Üí same partition
* Ensures ordering for that key

---

## How does **key affect partitioning** ‚≠ê

Default partitioner:

```
partition = hash(key) % number_of_partitions
```

Impact:

* Ordering guaranteed per key
* Bad keys ‚Üí partition skew
* Hot key ‚Üí hot partition

üí° **Senior insight**

> Most Kafka performance issues are key-design issues.

---

## What happens if **producer retries**?

### **Scenario**

* Network timeout
* Broker slow
* Leader election

Producer retries send again ‚Üí broker **may already have written the record**.

---

## How do **retries cause duplicates**?

Without idempotence:

1. Producer sends message
2. Broker writes it
3. Ack lost
4. Producer retries
5. Message written again

üí° **Interview one-liner**

> Retries + network failures = duplicates.

---

## What is **max.in.flight.requests.per.connection**?

### **Concept**

Controls:

> How many unacknowledged requests can be sent per broker connection.

Default:

* `5` (older)
* `1` recommended for strict ordering

---

### **Why it matters**

* > 1 ‚Üí higher throughput
* > 1 ‚Üí ordering can break on retries (without idempotence)

üí° **Senior rule**

> Idempotent producer + in-flight control = safe retries.

---

## How to achieve **exactly-once from producer side**?

### **Required configuration**

* `enable.idempotence=true`
* `acks=all`
* Proper retries
* Stable broker cluster

üí° **Important**

> This guarantees exactly-once *per partition write*, not end-to-end processing.

---

# 4Ô∏è‚É£ Consumers & Consumer Groups (üî• MUST MASTER)

---

## How does **Kafka consumer work**?

### **Concept**

Kafka consumer:

> **Pulls data from brokers and tracks offsets.**

Flow:

1. Poll broker
2. Fetch records
3. Process records
4. Commit offsets

üí° **Key idea**

> Consumers control when data is considered ‚Äúprocessed‚Äù.

---

## What is a **consumer group**?

### **Concept**

A consumer group is:

> **A set of consumers that cooperatively consume a topic.**

* Each partition ‚Üí only **one consumer in a group**
* Enables parallel processing

---

## Why are **consumer groups needed**?

They provide:

* Scalability
* Fault tolerance
* Load balancing

üí° **Interview one-liner**

> Consumer groups turn partitions into parallelism units.

---

## How Kafka ensures **one consumer per partition**?

Kafka guarantees:

* A partition is assigned to **only one consumer in a group**
* Coordinator manages assignments
* Prevents duplicate processing inside a group

---

## What happens when a **consumer dies**?

1. Heartbeats stop
2. Broker detects failure
3. Rebalance triggered
4. Partitions reassigned
5. New consumer resumes from last committed offset

üí° **Key point**

> Fault tolerance is achieved via rebalancing.

---

## What is **rebalancing**? ‚≠ê

### **Concept**

Rebalancing is:

> **Redistribution of partitions among consumers in a group.**

Triggered when:

* Consumer joins/leaves
* Topic partitions change
* Consumer crashes

---

## Why is **rebalancing expensive**?

Because:

* Consumers pause consumption
* State may need rebuilding
* Cache warm-up lost
* Processing stops temporarily

üí° **Senior insight**

> Rebalancing is correctness-first, availability-second.

---

## How do you **reduce rebalance impact**?

* Increase session timeout carefully
* Avoid frequent consumer restarts
* Use **static membership**
* Use **cooperative rebalancing**
* Keep processing inside `poll()` fast

---

## What is **cooperative rebalancing**?

### **Concept**

Instead of revoking all partitions:

> **Partitions are moved incrementally.**

Benefits:

* Less disruption
* Lower downtime
* Faster recovery

üí° **Interview gold**

> Cooperative rebalancing minimizes stop-the-world behavior.

---

## What is **consumer lag**?

### **Concept**

Consumer lag =

```
latest_offset ‚àí committed_offset
```

It indicates:

* How far behind a consumer is

---

## How do you **monitor lag**?

* Kafka metrics
* Consumer group commands
* Monitoring tools (Prometheus, Grafana)
* Alerts on sustained lag growth

üí° **Senior insight**

> Lag growth indicates capacity or processing problems.

---

## What happens if **consumer is slow**?

Effects:

* Lag increases
* Rebalance may occur
* Eventually consumer may be kicked out

Root causes:

* Heavy processing
* Blocking I/O
* Poor batching
* Slow downstream systems

---

## What is **poll()**?

### **Concept**

`poll()`:

> Fetches records **and sends heartbeats**.

It is **mandatory** for liveness.

---

## What is **max.poll.interval.ms**?

### **Concept**

Maximum time:

> Consumer is allowed to process records between polls.

If exceeded:

* Consumer considered dead
* Rebalance triggered

---

## What happens if **poll is not called in time**?

1. Broker assumes consumer is stuck
2. Consumer removed from group
3. Rebalance occurs
4. Partition reassigned
5. Duplicate processing may happen

üí° **Interview clarity**

> poll() is both fetch and heartbeat ‚Äî miss it and you‚Äôre out.

---

## ‚úÖ Final Interview-Ready Summary

### **Producers**

* Kafka producer is async & batch-oriented
* linger.ms & batch.size control throughput vs latency
* acks controls durability
* Retries can cause duplicates
* Idempotent producer prevents duplicates
* Keys control partitioning & ordering
* Exactly-once requires configuration

### **Consumers**

* Consumers pull data & manage offsets
* Consumer groups enable parallelism
* One consumer per partition per group
* Rebalancing ensures fault tolerance
* Rebalancing is expensive
* Cooperative rebalancing reduces disruption
* Consumer lag shows health
* poll() is critical for liveness
* max.poll.interval.ms protects group stability

---

Below is a **senior-level, concept-first explanation** of **Kafka Offset Management & Delivery Semantics**. This is **bank / FAANG / backend-heavy interview depth**‚Äîfocused on **failure scenarios, guarantees, and trade-offs**, not surface definitions.

---

# 5Ô∏è‚É£ Offset Management (‚≠ê Interview Favorite)

---

## What is an **offset**?

### **Concept**

An offset is:

> **A monotonically increasing position of a record within a partition.**

Key points:

* Offsets are **per partition**
* Offset = consumer‚Äôs progress marker
* Kafka does **not** track ‚Äúprocessed‚Äù messages‚Äîonly offsets

üí° **Interview one-liner**

> Offset is Kafka‚Äôs checkpoint, not a delivery receipt.

---

## Where are **offsets stored**?

### **Modern Kafka**

Offsets are stored in:

> `__consumer_offsets` **Kafka internal topic**

Benefits:

* Durable
* Replicated
* Scalable
* No external dependency (like Zookeeper)

üí° **Senior insight**

> Offsets are just Kafka messages consumed by Kafka itself.

---

## Auto commit vs Manual commit ‚≠ê

---

### **Auto Commit**

* Kafka commits offsets periodically
* Happens **independent of processing**
* Simple, but risky

‚ö†Ô∏è Risk:

* Message can be committed **before processing completes**

---

### **Manual Commit**

* Application controls **when** offsets are committed
* Commit **after processing**
* More code, more control

üí° **Interview stance**

> Auto commit favors simplicity; manual commit favors correctness.

---

## When would you use **manual commit**?

Use manual commit when:

* Processing is expensive
* Processing is non-idempotent
* You need **strong delivery guarantees**
* You integrate with DB / external systems

üí° **Senior rule**

> If processing matters, don‚Äôt auto-commit.

---

## What happens if **commit fails**?

### **Outcomes**

* Consumer may reprocess messages
* Duplicate processing possible
* Delivery semantics degrade to **at-least-once**

Kafka does **not** roll back processing‚Äîonly offsets.

üí° **Interview clarity**

> Commit failure never loses data‚Äîonly causes reprocessing.

---

## At-least-once vs At-most-once vs Exactly-once ‚≠ê

---

### **At-most-once**

* Commit **before processing**
* No duplicates
* Possible data loss

---

### **At-least-once**

* Commit **after processing**
* No data loss
* Possible duplicates

---

### **Exactly-once**

* Processed **once and only once**
* Requires:

  * Idempotence
  * Transactions
  * Careful design

üí° **Interview gold**

> Kafka defaults to at-least-once; exactly-once is engineered.

---

## How do you **avoid message loss**?

### **Strategies**

* `acks=all`
* Manual offset commit
* Commit after processing
* Retry on transient failures
* Avoid auto-commit for critical paths

üí° **Senior insight**

> Message loss happens when commits move ahead of reality.

---

## How do you **handle duplicate processing**?

### **Industry-grade solutions**

* Idempotent processing
* Deduplication keys
* Transactional writes
* Version checks
* External idempotency store

üí° **Interview one-liner**

> Duplicates are inevitable; correctness comes from idempotence.

---

## What happens if **consumer crashes before commit**?

### **Behavior**

* Offset not committed
* Partition reassigned
* New consumer starts from **last committed offset**
* Messages are reprocessed

üí° **Key point**

> Kafka prefers reprocessing over data loss.

---

## What is **commitSync vs commitAsync**?

---

### **commitSync**

* Blocks until commit succeeds
* Stronger guarantee
* Higher latency

---

### **commitAsync**

* Non-blocking
* Faster
* Commit may fail silently

üí° **Senior rule**

> Use commitSync at shutdown; commitAsync during normal flow.

---

# 6Ô∏è‚É£ Kafka Delivery Semantics (üî• VERY IMPORTANT)

---

## Explain **delivery guarantees in Kafka**

Kafka provides:

* **At-most-once**
* **At-least-once**
* **Exactly-once** (with configuration)

Guarantees depend on:

* Producer config
* Consumer commit strategy
* Transactions
* Failure handling

üí° **Interview clarity**

> Kafka gives tools, not magic guarantees.

---

## How Kafka achieves **at-least-once**

### **Mechanism**

* Producer retries on failure
* Consumer commits after processing

Result:

* Messages may be processed **more than once**
* No message loss

üí° **Trade-off**

> Reliability over duplication.

---

## How Kafka achieves **exactly-once** ‚≠ê

Exactly-once requires:

* **Idempotent producer**
* **Transactional producer**
* **Transactional consumer**
* Atomic offset + output commit

Kafka ensures:

> Message is processed **once** and its side-effects happen **once**

üí° **Important**

> Exactly-once is guaranteed **within Kafka**, not across arbitrary systems unless integrated carefully.

---

## What is a **transactional producer**?

### **Concept**

A transactional producer:

> Groups multiple writes into an atomic unit.

Features:

* Write to multiple partitions
* Write to multiple topics
* Commit offsets + output atomically

üí° **Interview insight**

> Transactions turn Kafka into a distributed commit system.

---

## What is **transactional.id**?

### **Concept**

`transactional.id`:

> Uniquely identifies a producer instance across restarts.

Used for:

* Fencing old producers
* Preventing zombie writes
* Maintaining EOS guarantees

üí° **Senior insight**

> transactional.id gives Kafka producer identity, not just connection identity.

---

## What happens during **producer transaction failure**?

### **Scenarios**

* Crash
* Timeout
* Broker failure

### **Kafka behavior**

* Transaction is **aborted**
* Partial writes are discarded
* Consumers won‚Äôt see uncommitted data (if configured)

üí° **Interview clarity**

> Transactions fail safely by hiding partial writes.

---

## Can consumers read **uncommitted messages**?

### **Depends on isolation.level**

* `read_committed` ‚Üí ‚ùå No
* `read_uncommitted` ‚Üí ‚úÖ Yes

üí° **Senior rule**

> Financial systems always use read_committed.

---

## What is **isolation.level**?

### **Concept**

Consumer setting that defines:

> Whether uncommitted transactional messages are visible.

Values:

* `read_committed`
* `read_uncommitted`

üí° **Interview one-liner**

> isolation.level controls visibility, not durability.

---

## ‚úÖ Final Interview-Ready Summary

### **Offsets**

* Offsets track consumer progress
* Stored in `__consumer_offsets`
* Auto commit is risky
* Manual commit gives control
* Commit failure causes reprocessing

### **Delivery Semantics**

* Kafka defaults to at-least-once
* At-most-once trades data loss for simplicity
* Exactly-once requires transactions
* Idempotence prevents duplicates
* transactional.id prevents zombie writes
* read_committed hides partial transactions

---

### üî• One-line senior takeaway

> Kafka guarantees **durable delivery**; correctness depends on how you manage offsets and transactions.

---

Below is a **senior-level, production-grade explanation** of **Kafka Replication, Fault Tolerance, Storage, and Retention** ‚Äî exactly the depth **banks and low-latency systems** expect. I‚Äôll focus on **failure behavior, guarantees, and trade-offs**, not surface definitions.

---

# 7Ô∏è‚É£ Replication & Fault Tolerance (üî• BANK FAVORITE)

---

## What is **replication factor**?

### **Concept**

Replication factor (RF) is:

> **The number of copies of each partition stored across different brokers.**

Example:

* RF = 3 ‚Üí 1 leader + 2 followers

### **Purpose**

* Fault tolerance
* High availability
* Data durability

üí° **Interview one-liner**

> Replication protects data; partitions provide scalability.

---

## Leader vs Follower

### **Leader**

* Handles **all reads and writes**
* Defines the authoritative log
* One per partition

### **Follower**

* Replicates data from leader
* Does not serve writes
* Can become leader on failure

üí° **Key insight**

> Kafka uses **leader-based replication**, not multi-leader.

---

## What is **ISR (In-Sync Replicas)** ‚≠ê

### **Concept**

ISR is:

> **The set of replicas that are fully caught up with the leader.**

Criteria to be in ISR:

* Replica is alive
* Replica is not lagging beyond configured threshold

üí° **Interview gold**

> ISR defines *who can be trusted* during failures.

---

## What happens if **ISR shrinks**?

### **Reasons**

* Follower is slow
* Network issue
* Broker overloaded
* Disk I/O lag

### **Effects**

* Fewer replicas eligible for leader election
* Reduced fault tolerance
* Higher risk of unavailability

üí° **Senior insight**

> Shrinking ISR is an early warning signal.

---

## What is **min.insync.replicas**?

### **Concept**

`min.insync.replicas` defines:

> **Minimum number of ISR replicas that must acknowledge a write for it to succeed (with acks=all).**

Example:

* RF = 3
* min.insync.replicas = 2

---

## What happens when **min ISR is not met**?

### **Scenario**

* ISR size < min.insync.replicas
* Producer uses `acks=all`

### **Result**

* Producer writes **fail**
* Kafka returns error
* Data is **not accepted**

üí° **Interview clarity**

> Kafka prefers availability loss over data loss.

---

## How Kafka handles **broker failure**?

### **Step-by-step**

1. Broker stops heartbeating
2. Controller detects failure
3. Partitions on that broker affected
4. New leaders elected from ISR
5. Clients update metadata
6. Traffic resumes

üí° **Senior takeaway**

> Failover is automatic, not instantaneous.

---

## How **leader election** works?

### **Rule**

> New leader is chosen **only from ISR**.

Why:

* ISR replicas have the most up-to-date data
* Prevents data loss

If ISR is empty:

* Partition becomes unavailable
* Depends on `unclean.leader.election`

---

## What happens during **network partition**?

### **Possible outcomes**

* Broker temporarily removed from ISR
* Leader may change
* Writes may fail (depending on ISR size)
* Consumers may see lag

Kafka chooses:

> **Consistency over availability** (with safe configs)

üí° **Bank-grade insight**

> Kafka is CP-leaning under partition (CAP theorem).

---

# 8Ô∏è‚É£ Storage & Retention (Often Missed)

---

## How Kafka stores data on disk?

### **Core design**

Kafka stores data as:

> **Append-only logs on disk.**

Characteristics:

* Sequential writes
* OS page cache usage
* No random updates
* Immutable records

üí° **Interview one-liner**

> Kafka treats disk as a sequential write buffer.

---

## What is a **log segment**?

### **Concept**

A partition is split into:

> **Multiple log segment files.**

Each segment:

* Has a base offset
* Is immutable once closed
* Enables efficient deletion

üí° **Why segments matter**

> Kafka deletes segments, not individual messages.

---

## What is **retention policy**?

### **Concept**

Retention policy defines:

> **How long or how much data Kafka keeps.**

Controlled by:

* Time
* Size
* Compaction (optional)

---

## Time-based vs Size-based retention

### **Time-based**

* Delete data older than X hours/days
* Most common

### **Size-based**

* Delete oldest data when size exceeds limit
* Useful for bounded storage

üí° **Senior insight**

> Retention is about storage management, not consumption.

---

## What happens when **retention expires**?

### **Process**

1. Old log segments identified
2. Entire segment deleted
3. Disk space reclaimed

‚ö†Ô∏è Messages may be deleted **even if not consumed**.

üí° **Interview clarity**

> Kafka retention is independent of consumers.

---

## Can Kafka delete **consumed messages**?

### ‚ùå **No (conceptually)**

Kafka does **not track consumption per message**.

* Consumers track offsets
* Retention deletes data based on policy

üí° **Interview one-liner**

> Kafka deletes by age/size, not by read status.

---

## What is **log compaction** ‚≠ê

### **Concept**

Log compaction keeps:

> **Only the latest value for each key**.

* Old versions removed
* Last write per key retained
* Key must be present

üí° **Key point**

> Compaction is about state, not history.

---

## Retention vs Compaction ‚Äî difference

| Retention              | Compaction           |
| ---------------------- | -------------------- |
| Time/size based        | Key based            |
| Deletes old data       | Deletes old versions |
| Good for event streams | Good for state       |
| Order matters          | Latest value matters |

üí° **Interview gold**

> Retention removes history; compaction preserves state.

---

## When would you use **log compaction**?

### **Real use cases**

* User profile updates
* Account balances
* Configuration topics
* Change-data-capture (CDC)
* Caches & materialized views

üí° **Senior insight**

> Use compaction when consumers care about *current state*, not past events.

---

## ‚úÖ Final Interview-Ready Summary

### **Replication & Fault Tolerance**

* Replication factor defines durability
* Leaders handle writes; followers replicate
* ISR is the trusted replica set
* Shrinking ISR reduces fault tolerance
* min.insync.replicas protects data correctness
* Kafka fails writes when safety guarantees can‚Äôt be met
* Leader election only happens from ISR
* Kafka prioritizes consistency during failures

### **Storage & Retention**

* Kafka uses append-only logs
* Partitions split into log segments
* Retention deletes entire segments
* Retention is independent of consumption
* Kafka never deletes messages ‚Äúbecause they were read‚Äù
* Log compaction keeps latest value per key
* Retention ‚â† Compaction
* Compaction is for stateful streams

---

### üî• One-line senior takeaway

> Kafka guarantees durability through replication, correctness through ISR, and scalability through immutable logs.

---

Below is a **senior-level, production-grade explanation** of **Kafka Performance & Tuning** and **Guarantees / Myths**. This is the depth expected in **banking, low-latency, and high-scale backend interviews**.

---

# 9Ô∏è‚É£ Performance & Tuning (‚≠ê Senior Signal)

---

## How to tune Kafka for **high throughput**?

### **Throughput mindset**

> Maximize data moved per unit time, tolerate some latency.

### **Key levers**

#### **Producer-side**

* Increase `batch.size`
* Increase `linger.ms`
* Enable compression
* Use async sends
* Increase `max.in.flight.requests.per.connection`
* Use fewer keys if ordering isn‚Äôt critical

#### **Broker-side**

* More partitions
* More disks (JBOD)
* Fast sequential storage
* Adequate page cache
* Proper replication factor (not excessive)

#### **Consumer-side**

* Increase `fetch.min.bytes`
* Increase `fetch.max.wait.ms`
* Parallelize consumers (consumer groups)
* Batch processing

üí° **Interview one-liner**

> Kafka throughput comes from batching + sequential IO + parallelism.

---

## How to tune Kafka for **low latency**?

### **Latency mindset**

> Deliver each message as fast and predictably as possible.

### **Key levers**

#### **Producer**

* `linger.ms = 0`
* Smaller `batch.size`
* Compression only if CPU allows
* `acks=1` (if durability tradeoff acceptable)

#### **Broker**

* Keep ISR healthy
* Avoid disk contention
* Use SSDs
* Avoid excessive replication

#### **Consumer**

* Small poll batches
* Fast processing
* Avoid blocking I/O in consumer thread

üí° **Senior tradeoff**

> You cannot optimize throughput and latency simultaneously.

---

## Compression types and tradeoffs

| Compression | CPU    | Compression Ratio | Latency | Use case          |
| ----------- | ------ | ----------------- | ------- | ----------------- |
| None        | Low    | ‚ùå                 | Lowest  | Ultra-low latency |
| GZIP        | High   | High              | High    | Network-bound     |
| Snappy      | Medium | Medium            | Low     | Balanced          |
| LZ4         | Low    | Medium            | Low     | High-throughput   |
| ZSTD        | Medium | High              | Medium  | Modern default    |

üí° **Interview insight**

> Compression often increases throughput by reducing network I/O.

---

## Effect of **message size** on performance

### **Small messages**

* High overhead per message
* Poor batching efficiency

### **Large messages**

* Memory pressure
* Longer GC pauses
* Network fragmentation
* Replication lag

üí° **Senior rule**

> Kafka performs best with **medium-sized batched messages**.

---

## What happens if messages are **too large**?

### **Problems**

* Producer exceptions
* Broker memory pressure
* Consumer fetch failures
* ISR shrink
* Latency spikes

Kafka has limits:

* `message.max.bytes`
* `max.request.size`
* `fetch.max.bytes`

üí° **Interview clarity**

> Kafka is not designed for very large payloads‚Äîstore data elsewhere.

---

## Zero-copy send in Kafka

### **Concept**

Kafka uses:

> **Zero-copy I/O (sendfile)**

Meaning:

* Data goes directly from disk ‚Üí network
* No user-space buffer copying
* Minimal CPU usage

üí° **Interview gold**

> Kafka avoids copying data into JVM memory whenever possible.

---

## Why Kafka prefers **sequential IO**?

### **Reason**

* Sequential disk writes are **orders of magnitude faster**
* Avoids seek time
* Works well with OS page cache

üí° **Senior insight**

> Kafka turns random workloads into sequential disk access.

---

## Producer vs Consumer bottleneck ‚Äî how to identify?

### **Symptoms**

| Symptom               | Likely bottleneck                 |
| --------------------- | --------------------------------- |
| High producer retries | Broker / network                  |
| High consumer lag     | Consumer                          |
| Broker CPU high       | Too many partitions / replication |
| Disk IO saturated     | Storage                           |

### **Tools**

* Lag metrics
* Broker metrics
* Producer error rates
* Consumer poll times

üí° **Interview clarity**

> Lag tells *where* the problem is, not *what* the problem is.

---

## How do you **scale Kafka consumers**?

### **Rules**

* One consumer per partition (per group)
* To scale ‚Üí increase partitions
* Scale processing inside consumer
* Use multiple consumer groups for fan-out

üí° **Senior rule**

> You can‚Äôt outscale partition count.

---

## How to handle **millions of messages per second**?

### **Architecture-level answers**

* Many partitions
* Many brokers
* Horizontal consumer scaling
* Efficient keys
* Batch processing
* Compression
* Avoid synchronous processing
* Downstream systems must also scale

üí° **Interview gold**

> Kafka throughput is an ecosystem problem, not just a broker problem.

---

# üîü Kafka Guarantees, Limits & Myths

---

## Is Kafka **exactly-once end-to-end**?

### ‚ùå **No (by default)**

Kafka provides:

* Exactly-once **within Kafka**
* End-to-end EOS requires:

  * Idempotent processing
  * Transactions
  * Careful DB integration

üí° **Interview one-liner**

> Exactly-once is a system property, not a Kafka default.

---

## Does Kafka guarantee **message order always**?

### ‚ùå **No**

Kafka guarantees ordering:

* **Only within a single partition**

Ordering is broken if:

* Multiple partitions
* Repartitioning
* Bad key design

üí° **Interview clarity**

> Ordering is scoped, not global.

---

## Can Kafka **lose messages**?

### ‚úÖ **Yes**, if misconfigured

Scenarios:

* `acks=0`
* Low replication factor
* `min.insync.replicas` too low
* Unclean leader election
* Disk corruption

üí° **Senior insight**

> Kafka trades availability for durability based on configuration.

---

## Is Kafka suitable for **request-response**?

### ‚ùå **No**

Why:

* High latency
* Asynchronous
* No direct correlation
* No guaranteed immediate response

Use Kafka for:

* Events
* Streams
* Pipelines

üí° **Interview one-liner**

> Kafka is for streams, not conversations.

---

## Can Kafka replace a **database**?

### ‚ùå **No**

Kafka:

* No random updates
* No ad-hoc queries
* Append-only
* No transactions across arbitrary records

Kafka complements databases, not replaces them.

üí° **Interview clarity**

> Kafka stores events; databases store state.

---

## Why Kafka is **not good for small workloads**?

### **Reasons**

* Operational overhead
* Cluster management cost
* Network hops
* Complex tuning

üí° **Senior rule**

> Kafka shines at scale; it‚Äôs overkill for small systems.

---

## What happens if **Zookeeper is down**?

### **Kafka behavior**

* Existing brokers continue serving traffic
* No new topic creation
* No leader election
* No partition reassignment

Kafka is:

> **Operational but not manageable**

üí° **Interview gold**

> Zookeeper failure limits control plane, not data plane.

---

## Kafka vs **Event Sourcing** ‚Äî relation?

### **Relation**

Kafka is often used as:

> **The event log backing event-sourced systems**

But Kafka **is not event sourcing itself**.

Event sourcing needs:

* Schema evolution
* Versioning
* Business semantics
* Replay logic

üí° **Senior insight**

> Kafka is infrastructure; event sourcing is an architectural pattern.

---

## ‚úÖ Final Interview-Ready Summary

### **Performance**

* Throughput = batching + compression + partitions
* Latency = small batches + fewer guarantees
* Message size matters
* Kafka excels at sequential IO
* Consumers scale only with partitions
* Millions/sec requires system-wide scaling

### **Guarantees & Limits**

* Exactly-once is not automatic
* Ordering is partition-scoped
* Kafka can lose data if misconfigured
* Not suitable for request-response
* Not a database replacement
* Overkill for small systems
* Zookeeper outage affects control, not data
* Kafka enables event sourcing but doesn‚Äôt replace it

---

### üî• One-line senior takeaway

> Kafka is a **high-throughput, durable event backbone**‚Äîperformance and guarantees depend entirely on how you design and configure it.

---

Below is a **senior-level, scenario-driven Kafka walkthrough**. This is **highest-signal interview content**‚Äîfocused on **diagnosis, root causes, and design decisions**, exactly how strong backend / bank interviews evaluate Kafka depth.

---

# üî• 1Ô∏è‚É£3Ô∏è‚É£ Scenario-Based Kafka Questions (HIGHEST SIGNAL)

---

## üü• Consumer lag keeps increasing ‚Äî how do you debug? ‚≠ê

### **Senior mindset**

Lag increasing means:

> **Consumption rate < production rate**

Now find **where** the bottleneck is.

---

### **Step-by-step diagnosis**

#### 1Ô∏è‚É£ Confirm lag source

* Is lag growing for **all partitions** or only some?
* One partition hot ‚Üí key skew
* All partitions ‚Üí systemic issue

---

#### 2Ô∏è‚É£ Check consumer health

* Consumer CPU / memory
* GC pauses
* Blocking I/O inside processing
* Poll loop too slow

---

#### 3Ô∏è‚É£ Check poll configuration

* `max.poll.interval.ms` too low?
* `max.poll.records` too high?
* Long processing between polls?

---

#### 4Ô∏è‚É£ Check downstream systems

* DB slow?
* External API latency?
* Retry storms?

---

#### 5Ô∏è‚É£ Check scaling limits

* Partitions < consumers?
* Consumer group maxed out?

üí° **Interview one-liner**

> Lag is a symptom; the root cause is always processing, skew, or capacity.

---

## üü® Messages are duplicated ‚Äî root causes?

### **Common causes**

* Producer retries without idempotence
* Consumer crash after processing but before commit
* Rebalance during processing
* Manual offset reset
* At-least-once semantics misunderstood

üí° **Senior insight**

> Duplicates are expected in Kafka; correctness comes from idempotent processing.

---

## üü• Producer is slow ‚Äî what do you check?

### **Producer-side**

* `acks=all` + low ISR?
* Small `batch.size`
* `linger.ms = 0`
* Compression disabled
* High retry rate

---

### **Broker-side**

* ISR shrinking
* Disk I/O saturation
* Network latency
* Leader imbalance

---

### **Network**

* TLS overhead
* Cross-region latency

üí° **Interview clarity**

> Producer slowness is often broker or disk slowness in disguise.

---

## üü® Kafka cluster disk usage is growing ‚Äî why?

### **Primary reasons**

* Retention too high
* Consumers stopped (but retention doesn‚Äôt care)
* Log compaction enabled incorrectly
* Large message sizes
* Failed cleanup due to disk pressure

üí° **Key reminder**

> Kafka deletes by **retention**, not by consumption.

---

## üü• Rebalance happening frequently ‚Äî how to fix?

### **Root causes**

* Consumer crashes
* Long processing inside poll
* `max.poll.interval.ms` exceeded
* Scaling consumers too aggressively
* Unstable deployments

---

### **Fixes**

* Increase `max.poll.interval.ms`
* Reduce per-poll processing time
* Use **cooperative rebalancing**
* Use static membership
* Avoid frequent restarts

üí° **Interview gold**

> Rebalancing is correctness-first, availability-second.

---

## üü® One consumer processing slower than others ‚Äî solution?

### **Likely cause**

* Partition skew
* Hot key
* One partition overloaded

---

### **Solutions**

* Redesign key
* Split hot topic
* Increase partitions (carefully)
* Parallelize processing inside consumer
* Offload heavy work asynchronously

üí° **Senior insight**

> Kafka parallelism is partition-bound, not thread-bound.

---

## üü• Topic throughput suddenly drops ‚Äî steps to debug

### **Step sequence**

1. Check broker metrics (CPU, disk, ISR)
2. Check partition leadership imbalance
3. Check producer retries / timeouts
4. Check consumer lag
5. Check network & disk latency

üí° **Interview clarity**

> Throughput drops are usually disk or ISR related.

---

## üü© How do you design Kafka for **exactly-once processing**?

### **Required components**

* Idempotent producer
* Transactional producer
* `transactional.id`
* `acks=all`
* `min.insync.replicas ‚â• 2`
* Consumer with `read_committed`
* Atomic offset + output commit

üí° **Senior framing**

> Exactly-once is a pipeline property, not a Kafka default.

---

## üü¶ Kafka vs DB for audit logs ‚Äî why Kafka?

### **Kafka advantages**

* Immutable history
* High throughput
* Replayable
* Fan-out to multiple consumers
* Cheap writes

### **DB limitations**

* Expensive writes at scale
* Hard to replay history
* Limited fan-out

üí° **Interview one-liner**

> Kafka is for *event history*; DBs are for *current state*.

---

## ‚≠ê Explain a **real Kafka production issue you fixed**

### **Strong interview structure**

**Problem**
Consumer lag kept growing during peak hours.

**Diagnosis**

* One partition had 60% of traffic
* Key was userId, one large customer dominated

**Fix**

* Introduced composite key `(userId + hash(eventType))`
* Repartitioned topic
* Added consumer-side async processing

**Result**

* Lag stabilized
* Throughput improved 3√ó
* No more rebalance storms

---

# üß† COMMONLY MISSED BUT ASKED

---

## Difference between **Kafka and Event Bus**

| Kafka               | Event Bus            |
| ------------------- | -------------------- |
| Persistent log      | Transient messages   |
| Replayable          | Often not            |
| Consumer-controlled | Broker-controlled    |
| Streaming-oriented  | Integration-oriented |

üí° **One-liner**

> Kafka is a log; an event bus is a router.

---

## Push vs Pull model

### **Kafka = Pull**

* Consumers control pace
* Natural backpressure
* Better fault tolerance

### **Push systems**

* Broker pushes messages
* Consumer overload possible

üí° **Interview insight**

> Pull enables backpressure; push causes overload.

---

## Backpressure handling in Kafka

Kafka handles backpressure via:

* Consumer pull rate
* Offset lag
* Retention buffering
* Batching

üí° **Key point**

> Kafka absorbs spikes by design, not by blocking producers.

---

## Why Kafka consumers **pull**, not push?

Because pull:

* Prevents consumer overload
* Simplifies scaling
* Allows consumers to pause/resume
* Makes lag observable

üí° **Interview gold**

> Pull puts flow control in consumer hands.

---

## What happens if consumer **commits offset too early**?

### **Outcome**

* Message considered processed
* Consumer crashes
* Message lost forever

üí° **Senior rule**

> Commit is a promise‚Äîdon‚Äôt lie.

---

## What happens if **offset is reset**?

### **Effects**

* Consumer may reprocess old data
* Or skip unprocessed data
* Depends on reset policy

---

## `earliest` vs `latest` offset reset

| earliest             | latest         |
| -------------------- | -------------- |
| Start from beginning | Start from now |
| Reprocess history    | Skip past data |
| Safer                | Faster startup |

üí° **Interview clarity**

> earliest favors correctness; latest favors speed.

---

## ‚úÖ Final Senior-Level Takeaways

* Lag = processing or scaling problem
* Duplicates are normal; idempotence is mandatory
* Producers slow due to disk/ISR/network
* Kafka retention is independent of consumption
* Rebalances are expensive‚Äîavoid churn
* Parallelism is partition-bound
* Exactly-once requires careful design
* Kafka is ideal for audit/event history
* Pull model enables backpressure
* Early commits cause data loss
* Offset resets can reprocess or skip data

---

### üî• Final one-liner

> Kafka guarantees **durability and scalability**‚Äî**correctness is your responsibility**.

Below is a **senior-level Kafka interview question list** tailored for **Backend / Java developers (~4 years experience)**.
This is **exactly what banks, fintech, and product companies ask**, not beginner Kafka trivia.

I‚Äôve grouped questions by **signal strength** and **real interview patterns**.

---

# üî• APACHE KAFKA INTERVIEW QUESTIONS (SENIOR BACKEND)

---

## 1Ô∏è‚É£ Kafka Fundamentals (Still Asked, But Deep)

1. What is Kafka and why is it used?
2. Kafka vs traditional message queue (RabbitMQ / ActiveMQ) ‚≠ê
3. What problems does Kafka solve?
4. Is Kafka a message queue or a streaming platform?
5. Why Kafka is fast?
6. What is a Kafka cluster?
7. What is a Kafka broker?
8. What is a topic?
9. What is a partition?
10. Why partitions are important? ‚≠ê

---

## 2Ô∏è‚É£ Topics, Partitions & Ordering (VERY COMMON)

11. How does Kafka guarantee ordering?
12. Is ordering guaranteed across partitions?
13. How do you decide number of partitions?
14. Can you change number of partitions later?
15. What happens to ordering when partitions increase?
16. What happens if a partition leader fails?
17. How does Kafka handle partition rebalancing?
18. What is partition skew?
19. What happens if one partition is very hot? ‚≠ê
20. How do you handle uneven message load?

---

## 3Ô∏è‚É£ Producers (HIGH SIGNAL)

21. How does Kafka producer work internally?
22. What is producer batching?
23. What is `linger.ms`?
24. What is `batch.size`?
25. What is `acks`?
26. Difference between `acks=0`, `1`, `all` ‚≠ê
27. What is idempotent producer?
28. How does Kafka guarantee no duplicate messages?
29. What is message key?
30. How key affects partitioning ‚≠ê
31. What happens if producer retries?
32. How do retries cause duplicates?
33. What is `max.in.flight.requests.per.connection`?
34. How to achieve exactly-once from producer side?

---

## 4Ô∏è‚É£ Consumers & Consumer Groups (üî• MUST MASTER)

35. How does Kafka consumer work?
36. What is a consumer group?
37. Why consumer groups are needed?
38. How Kafka ensures each partition is consumed by only one consumer?
39. What happens when a consumer dies?
40. What is rebalancing? ‚≠ê
41. Why rebalancing is expensive?
42. How do you reduce rebalance impact?
43. What is cooperative rebalancing?
44. What is consumer lag?
45. How do you monitor lag?
46. What happens if consumer is slow?
47. What is `poll()`?
48. What is `max.poll.interval.ms`?
49. What happens if poll is not called in time?

---

## 5Ô∏è‚É£ Offset Management (INTERVIEW FAVORITE)

50. What is an offset?
51. Where are offsets stored?
52. Auto commit vs manual commit ‚≠ê
53. When would you use manual commit?
54. What happens if commit fails?
55. At-least-once vs at-most-once vs exactly-once ‚≠ê
56. How to avoid message loss?
57. How to handle duplicate processing?
58. What happens if consumer crashes before commit?
59. What is commitSync vs commitAsync?

---

## 6Ô∏è‚É£ Kafka Delivery Semantics (VERY IMPORTANT)

60. Explain delivery guarantees in Kafka
61. How Kafka achieves at-least-once
62. How Kafka achieves exactly-once ‚≠ê
63. What is transactional producer?
64. What is transactional.id?
65. What happens during producer transaction failure?
66. Can consumers read uncommitted messages?
67. What is isolation.level?

---

## 7Ô∏è‚É£ Replication & Fault Tolerance (BANK FAVORITE)

68. What is replication factor?
69. Leader vs follower
70. What is ISR (In-Sync Replicas)? ‚≠ê
71. What happens if ISR shrinks?
72. What is `min.insync.replicas`?
73. What happens when min ISR is not met?
74. How Kafka handles broker failure?
75. How leader election works?
76. What happens during network partition?

---

## 8Ô∏è‚É£ Storage & Retention (Often Missed)

77. How Kafka stores data on disk?
78. What is log segment?
79. What is retention policy?
80. Time-based vs size-based retention
81. What happens when retention expires?
82. Can Kafka delete consumed messages?
83. What is log compaction ‚≠ê
84. Retention vs compaction difference
85. When would you use log compaction?

---

## 9Ô∏è‚É£ Performance & Tuning (SENIOR SIGNAL)

86. How to tune Kafka for high throughput?
87. How to tune Kafka for low latency?
88. Compression types and tradeoffs
89. Effect of message size on performance
90. What happens if messages are too large?
91. Zero-copy send in Kafka
92. Why Kafka prefers sequential IO?
93. Producer vs consumer bottleneck ‚Äî how to identify?
94. How do you scale Kafka consumers?
95. How to handle millions of messages per second?

---

## üîü Kafka Guarantees, Limits & Myths

96. Is Kafka exactly-once end-to-end?
97. Does Kafka guarantee message order always?
98. Can Kafka lose messages?
99. Is Kafka suitable for request-response?
100. Can Kafka replace a database?
101. Why Kafka is not good for small workloads?
102. What happens if Zookeeper is down?
103. Kafka vs Event Sourcing ‚Äî relation?

---

## 1Ô∏è‚É£1Ô∏è‚É£ Kafka in Real Production (VERY IMPORTANT)

104. How do you version Kafka messages?
105. How do you handle schema evolution?
106. Avro vs JSON vs Protobuf ‚≠ê
107. What happens if consumer gets incompatible schema?
108. How do you replay messages?
109. How do you reprocess old data?
110. How do you handle poison messages?
111. What is DLQ (Dead Letter Queue)?
112. How do you ensure idempotent consumers?
113. How do you pause/resume consumption?

---

## 1Ô∏è‚É£2Ô∏è‚É£ Security (Banks LOVE This)

114. How Kafka authentication works?
115. SASL vs SSL
116. How authorization works in Kafka?
117. How do ACLs work?
118. How do you secure topics?
119. How do you encrypt data in transit?
120. How do you handle secrets?

---

## 1Ô∏è‚É£3Ô∏è‚É£ Scenario-Based Kafka Questions (üî• HIGHEST SIGNAL)

121. Consumer lag keeps increasing ‚Äî how do you debug? ‚≠ê
122. Messages are duplicated ‚Äî root causes?
123. Producer is slow ‚Äî what do you check?
124. Kafka cluster disk usage is growing ‚Äî why?
125. Rebalance happening frequently ‚Äî how to fix?
126. One consumer processing slower than others ‚Äî solution?
127. Topic throughput suddenly drops ‚Äî steps to debug
128. How do you design Kafka for exactly-once processing?
129. Kafka vs DB for audit logs ‚Äî why Kafka?
130. Explain a real Kafka production issue you fixed ‚≠ê

---

## üß† COMMONLY MISSED BUT ASKED

131. Difference between Kafka and Event Bus
132. Push vs pull model
133. Backpressure handling in Kafka
134. Why Kafka consumers pull, not push?
135. What happens if consumer commits offset too early?
136. What happens if offset is reset?
137. earliest vs latest offset reset

---

## ‚úÖ FINAL VERDICT

If you can confidently explain:

* **Partitions**
* **Consumer groups**
* **Offsets**
* **ISR & replication**
* **Delivery semantics**
* **Lag & rebalancing**

üëâ You are **Kafka-interview ready** for **banks + big tech**.

---


